{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7bd4939-617b-40d4-80f6-9a803fa1b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52766694-605c-4439-8711-e7b7e946d762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
      "1   2     120000    2          2         2   26     -1      2      0      0   \n",
      "2   3      90000    2          2         2   34      0      0      0      0   \n",
      "3   4      50000    2          2         1   37      0      0      0      0   \n",
      "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
      "\n",
      "   ...  Credit_UTL4  Credit_UTL5  Credit_UTL6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  ...     0.000000     0.000000     0.000000         0       689         0   \n",
      "1  ...     0.027267     0.028792     0.027175         0      1000      1000   \n",
      "2  ...     0.159233     0.166089     0.172767      1518      1500      1000   \n",
      "3  ...     0.566280     0.579180     0.590940      2000      2019      1200   \n",
      "4  ...     0.418800     0.382920     0.382620      2000     36681     10000   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
      "0         0         0         0                           1  \n",
      "1      1000         0      2000                           1  \n",
      "2      1000      1000      5000                           0  \n",
      "3      1100      1069      1000                           0  \n",
      "4      9000       689       679                           0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File path to your dataset\n",
    "file_path = r\"C:\\Users\\welcome\\Desktop\\Customer Credit Risk Prediction project\\default of credit card clients.xls\"\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(file_path, header=1)  # Adjust header if necessary\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de975016-a13c-41e6-9785-689f28dd463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the dataset (rows, columns):\n",
      "(30000, 31)\n",
      "\n",
      "Dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 31 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   ID                          30000 non-null  int64  \n",
      " 1   LIMIT_BAL                   30000 non-null  int64  \n",
      " 2   SEX                         30000 non-null  int64  \n",
      " 3   EDUCATION                   30000 non-null  int64  \n",
      " 4   MARRIAGE                    30000 non-null  int64  \n",
      " 5   AGE                         30000 non-null  int64  \n",
      " 6   PAY_0                       30000 non-null  int64  \n",
      " 7   PAY_2                       30000 non-null  int64  \n",
      " 8   PAY_3                       30000 non-null  int64  \n",
      " 9   PAY_4                       30000 non-null  int64  \n",
      " 10  PAY_5                       30000 non-null  int64  \n",
      " 11  PAY_6                       30000 non-null  int64  \n",
      " 12  BILL_AMT1                   30000 non-null  int64  \n",
      " 13  BILL_AMT2                   30000 non-null  int64  \n",
      " 14  BILL_AMT3                   30000 non-null  int64  \n",
      " 15  BILL_AMT4                   30000 non-null  int64  \n",
      " 16  BILL_AMT5                   30000 non-null  int64  \n",
      " 17  BILL_AMT6                   30000 non-null  int64  \n",
      " 18  Credit_UTL1                 30000 non-null  float64\n",
      " 19  Credit_UTL2                 30000 non-null  float64\n",
      " 20  Credit_UTL3                 30000 non-null  float64\n",
      " 21  Credit_UTL4                 30000 non-null  float64\n",
      " 22  Credit_UTL5                 30000 non-null  float64\n",
      " 23  Credit_UTL6                 30000 non-null  float64\n",
      " 24  PAY_AMT1                    30000 non-null  int64  \n",
      " 25  PAY_AMT2                    30000 non-null  int64  \n",
      " 26  PAY_AMT3                    30000 non-null  int64  \n",
      " 27  PAY_AMT4                    30000 non-null  int64  \n",
      " 28  PAY_AMT5                    30000 non-null  int64  \n",
      " 29  PAY_AMT6                    30000 non-null  int64  \n",
      " 30  default payment next month  30000 non-null  int64  \n",
      "dtypes: float64(6), int64(25)\n",
      "memory usage: 7.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check the shape of the dataset\n",
    "print(\"\\nShape of the dataset (rows, columns):\")\n",
    "print(data.shape)\n",
    "\n",
    "# Display information about the dataset\n",
    "print(\"\\nDataset information:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb47d35c-b16c-4bbf-9ab2-bb1b51e4bb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names:\n",
      "Index(['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0',\n",
      "       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
      "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'Credit_UTL1',\n",
      "       'Credit_UTL2', 'Credit_UTL3', 'Credit_UTL4', 'Credit_UTL5',\n",
      "       'Credit_UTL6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4',\n",
      "       'PAY_AMT5', 'PAY_AMT6', 'default payment next month'],\n",
      "      dtype='object')\n",
      "\n",
      "Statistical Summary:\n",
      "                 ID       LIMIT_BAL           SEX     EDUCATION      MARRIAGE  \\\n",
      "count  30000.000000    30000.000000  30000.000000  30000.000000  30000.000000   \n",
      "mean   15000.500000   167484.322667      1.603733      1.853133      1.551867   \n",
      "std     8660.398374   129747.661567      0.489129      0.790349      0.521970   \n",
      "min        1.000000    10000.000000      1.000000      0.000000      0.000000   \n",
      "25%     7500.750000    50000.000000      1.000000      1.000000      1.000000   \n",
      "50%    15000.500000   140000.000000      2.000000      2.000000      2.000000   \n",
      "75%    22500.250000   240000.000000      2.000000      2.000000      2.000000   \n",
      "max    30000.000000  1000000.000000      2.000000      6.000000      3.000000   \n",
      "\n",
      "                AGE         PAY_0         PAY_2         PAY_3         PAY_4  \\\n",
      "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
      "mean      35.485500     -0.016700     -0.133767     -0.166200     -0.220667   \n",
      "std        9.217904      1.123802      1.197186      1.196868      1.169139   \n",
      "min       21.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
      "25%       28.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
      "50%       34.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%       41.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max       79.000000      8.000000      8.000000      8.000000      8.000000   \n",
      "\n",
      "       ...   Credit_UTL4   Credit_UTL5   Credit_UTL6       PAY_AMT1  \\\n",
      "count  ...  30000.000000  30000.000000  30000.000000   30000.000000   \n",
      "mean   ...      0.359503      0.333108      0.318585    5663.580500   \n",
      "std    ...      0.368686      0.350542      0.345301   16563.280354   \n",
      "min    ...     -1.374500     -0.876743     -1.509530       0.000000   \n",
      "25%    ...      0.014299      0.011133      0.007800    1000.000000   \n",
      "50%    ...      0.242066      0.212026      0.185224    2100.000000   \n",
      "75%    ...      0.667937      0.602245      0.582169    5006.000000   \n",
      "max    ...      5.146850      4.935500      3.885550  873552.000000   \n",
      "\n",
      "           PAY_AMT2      PAY_AMT3       PAY_AMT4       PAY_AMT5  \\\n",
      "count  3.000000e+04   30000.00000   30000.000000   30000.000000   \n",
      "mean   5.921163e+03    5225.68150    4826.076867    4799.387633   \n",
      "std    2.304087e+04   17606.96147   15666.159744   15278.305679   \n",
      "min    0.000000e+00       0.00000       0.000000       0.000000   \n",
      "25%    8.330000e+02     390.00000     296.000000     252.500000   \n",
      "50%    2.009000e+03    1800.00000    1500.000000    1500.000000   \n",
      "75%    5.000000e+03    4505.00000    4013.250000    4031.500000   \n",
      "max    1.684259e+06  896040.00000  621000.000000  426529.000000   \n",
      "\n",
      "            PAY_AMT6  default payment next month  \n",
      "count   30000.000000                30000.000000  \n",
      "mean     5215.502567                    0.221200  \n",
      "std     17777.465775                    0.415062  \n",
      "min         0.000000                    0.000000  \n",
      "25%       117.750000                    0.000000  \n",
      "50%      1500.000000                    0.000000  \n",
      "75%      4000.000000                    0.000000  \n",
      "max    528666.000000                    1.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display column names\n",
    "print(\"Column Names:\")\n",
    "print(data.columns)\n",
    "\n",
    "# Display statistical summary of the dataset\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2962debf-f4a7-4c02-bc3a-0f261178c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Select categorical columns\n",
    "categorical_cols = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "\n",
    "# Apply one-hot encoding\n",
    "encoder = OneHotEncoder(drop='first')  # Remove the `sparse` parameter\n",
    "encoded_data = encoder.fit_transform(data[categorical_cols]).toarray()  # Convert sparse matrix to dense array\n",
    "\n",
    "# Convert to DataFrame and merge with original data\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "data = pd.concat([data.drop(columns=categorical_cols), encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7253e2c-d99d-4a0a-8217-855278c04e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  LIMIT_BAL  AGE  PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  PAY_6  BILL_AMT1  \\\n",
      "0   1      20000   24      2      2     -1     -1     -2     -2       3913   \n",
      "1   2     120000   26     -1      2      0      0      0      2       2682   \n",
      "2   3      90000   34      0      0      0      0      0      0      29239   \n",
      "3   4      50000   37      0      0      0      0      0      0      46990   \n",
      "4   5      50000   57     -1      0     -1      0      0      0       8617   \n",
      "\n",
      "   ...  SEX_2  EDUCATION_1  EDUCATION_2  EDUCATION_3  EDUCATION_4  \\\n",
      "0  ...    1.0          0.0          1.0          0.0          0.0   \n",
      "1  ...    1.0          0.0          1.0          0.0          0.0   \n",
      "2  ...    1.0          0.0          1.0          0.0          0.0   \n",
      "3  ...    1.0          0.0          1.0          0.0          0.0   \n",
      "4  ...    0.0          0.0          1.0          0.0          0.0   \n",
      "\n",
      "   EDUCATION_5  EDUCATION_6  MARRIAGE_1  MARRIAGE_2  MARRIAGE_3  \n",
      "0          0.0          0.0         1.0         0.0         0.0  \n",
      "1          0.0          0.0         0.0         1.0         0.0  \n",
      "2          0.0          0.0         0.0         1.0         0.0  \n",
      "3          0.0          0.0         1.0         0.0         0.0  \n",
      "4          0.0          0.0         1.0         0.0         0.0  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "789d6bfe-2be0-42ba-8d05-2f9b938e8011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (30000, 37)\n",
      "Target shape: (30000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_column = 'default payment next month'\n",
    "features = data.drop(columns=[target_column])  # Drop the target column\n",
    "target = data[target_column]\n",
    "\n",
    "print(\"Features shape:\", features.shape)\n",
    "print(\"Target shape:\", target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f19dfa-ec78-49cc-a602-2fdccf09043c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (24000, 37)\n",
      "Testing set shape: (6000, 37)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42, stratify=target\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1640bd7c-907a-45ef-908a-66880caa89a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data (using the same scaler parameters)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9025dc0e-795d-4c81-8bee-19a2cbdcbb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 31 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   ID                          30000 non-null  int64  \n",
      " 1   LIMIT_BAL                   30000 non-null  int64  \n",
      " 2   SEX                         30000 non-null  int64  \n",
      " 3   EDUCATION                   30000 non-null  int64  \n",
      " 4   MARRIAGE                    30000 non-null  int64  \n",
      " 5   AGE                         30000 non-null  int64  \n",
      " 6   PAY_0                       30000 non-null  int64  \n",
      " 7   PAY_2                       30000 non-null  int64  \n",
      " 8   PAY_3                       30000 non-null  int64  \n",
      " 9   PAY_4                       30000 non-null  int64  \n",
      " 10  PAY_5                       30000 non-null  int64  \n",
      " 11  PAY_6                       30000 non-null  int64  \n",
      " 12  BILL_AMT1                   30000 non-null  int64  \n",
      " 13  BILL_AMT2                   30000 non-null  int64  \n",
      " 14  BILL_AMT3                   30000 non-null  int64  \n",
      " 15  BILL_AMT4                   30000 non-null  int64  \n",
      " 16  BILL_AMT5                   30000 non-null  int64  \n",
      " 17  BILL_AMT6                   30000 non-null  int64  \n",
      " 18  Credit_UTL1                 30000 non-null  float64\n",
      " 19  Credit_UTL2                 30000 non-null  float64\n",
      " 20  Credit_UTL3                 30000 non-null  float64\n",
      " 21  Credit_UTL4                 30000 non-null  float64\n",
      " 22  Credit_UTL5                 30000 non-null  float64\n",
      " 23  Credit_UTL6                 30000 non-null  float64\n",
      " 24  PAY_AMT1                    30000 non-null  int64  \n",
      " 25  PAY_AMT2                    30000 non-null  int64  \n",
      " 26  PAY_AMT3                    30000 non-null  int64  \n",
      " 27  PAY_AMT4                    30000 non-null  int64  \n",
      " 28  PAY_AMT5                    30000 non-null  int64  \n",
      " 29  PAY_AMT6                    30000 non-null  int64  \n",
      " 30  default payment next month  30000 non-null  int64  \n",
      "dtypes: float64(6), int64(25)\n",
      "memory usage: 7.1 MB\n",
      "None\n",
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
      "1   2     120000    2          2         2   26     -1      2      0      0   \n",
      "2   3      90000    2          2         2   34      0      0      0      0   \n",
      "3   4      50000    2          2         1   37      0      0      0      0   \n",
      "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
      "\n",
      "   ...  Credit_UTL4  Credit_UTL5  Credit_UTL6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  ...     0.000000     0.000000     0.000000         0       689         0   \n",
      "1  ...     0.027267     0.028792     0.027175         0      1000      1000   \n",
      "2  ...     0.159233     0.166089     0.172767      1518      1500      1000   \n",
      "3  ...     0.566280     0.579180     0.590940      2000      2019      1200   \n",
      "4  ...     0.418800     0.382920     0.382620      2000     36681     10000   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
      "0         0         0         0                           1  \n",
      "1      1000         0      2000                           1  \n",
      "2      1000      1000      5000                           0  \n",
      "3      1100      1069      1000                           0  \n",
      "4      9000       689       679                           0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Training and Evaluating: Logistic Regression\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.71      0.78      4673\n",
      "           1       0.37      0.61      0.46      1327\n",
      "\n",
      "    accuracy                           0.69      6000\n",
      "   macro avg       0.62      0.66      0.62      6000\n",
      "weighted avg       0.76      0.69      0.71      6000\n",
      "\n",
      "ROC-AUC Score: 0.7102\n",
      "Confusion Matrix:\n",
      "[[3316 1357]\n",
      " [ 518  809]]\n",
      "--------------------------------------------------\n",
      "Training and Evaluating: Random Forest\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      4673\n",
      "           1       0.64      0.33      0.43      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.74      0.64      0.66      6000\n",
      "weighted avg       0.79      0.81      0.79      6000\n",
      "\n",
      "ROC-AUC Score: 0.7624\n",
      "Confusion Matrix:\n",
      "[[4427  246]\n",
      " [ 893  434]]\n",
      "--------------------------------------------------\n",
      "Training and Evaluating: XGBoost\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      4673\n",
      "           1       0.47      0.59      0.52      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.67      0.70      0.68      6000\n",
      "weighted avg       0.78      0.76      0.77      6000\n",
      "\n",
      "ROC-AUC Score: 0.7560\n",
      "Confusion Matrix:\n",
      "[[3799  874]\n",
      " [ 549  778]]\n",
      "--------------------------------------------------\n",
      "Training and Evaluating: Support Vector Machine\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85      4673\n",
      "           1       0.49      0.56      0.53      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.68      0.70      0.69      6000\n",
      "weighted avg       0.79      0.78      0.78      6000\n",
      "\n",
      "ROC-AUC Score: 0.7552\n",
      "Confusion Matrix:\n",
      "[[3905  768]\n",
      " [ 581  746]]\n",
      "--------------------------------------------------\n",
      "Training and Evaluating: K-Nearest Neighbors\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87      4673\n",
      "           1       0.53      0.32      0.40      1327\n",
      "\n",
      "    accuracy                           0.79      6000\n",
      "   macro avg       0.68      0.62      0.64      6000\n",
      "weighted avg       0.76      0.79      0.77      6000\n",
      "\n",
      "ROC-AUC Score: 0.6830\n",
      "Confusion Matrix:\n",
      "[[4295  378]\n",
      " [ 901  426]]\n",
      "--------------------------------------------------\n",
      "Training and Evaluating: Naive Bayes\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.72      0.78      4673\n",
      "           1       0.37      0.59      0.45      1327\n",
      "\n",
      "    accuracy                           0.69      6000\n",
      "   macro avg       0.61      0.65      0.62      6000\n",
      "weighted avg       0.75      0.69      0.71      6000\n",
      "\n",
      "ROC-AUC Score: 0.7074\n",
      "Confusion Matrix:\n",
      "[[3343 1330]\n",
      " [ 547  780]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = r\"C:\\Users\\welcome\\Desktop\\Customer Credit Risk Prediction project\\default of credit card clients.xls\"\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(file_path, skiprows=1)  # Skip the first row as it contains metadata\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(data.info())\n",
    "print(data.head())\n",
    "\n",
    "# Define target and features\n",
    "target_column = 'default payment next month'\n",
    "features = data.drop(columns=[target_column])\n",
    "target = data[target_column]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42, stratify=target\n",
    ")\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define a function to evaluate and print model performance\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model and print classification report, ROC-AUC score, and confusion matrix.\n",
    "    \"\"\"\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Metrics\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Define and train multiple models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(), random_state=42, eval_metric='logloss'),\n",
    "    \"Support Vector Machine\": SVC(probability=True, class_weight='balanced', random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training and Evaluating: {model_name}\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    evaluate_model(model, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90412d90-6ffe-4c08-9928-ec2f40b9dbec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
